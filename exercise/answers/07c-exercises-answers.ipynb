{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b361aa49-a247-4b15-8f83-2055f7ed22d6",
   "metadata": {},
   "source": [
    "# Practice exercises \\#7 with answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36605210-77ea-461d-90b2-69be81d71510",
   "metadata": {},
   "source": [
    "For the following exercises, you will use the text file with the Oliver Twist book, which you can download from https://gutenberg.org/cache/epub/730/pg730.txt and load it as a file, or alternatively access it through an HTTP request, as you prefer.\n",
    "\n",
    "**Note:** For this set of exercises, you should remove all the punctuation prior to processing the text. To do this, you can use the following, where *text* is the variable where you want to remove the punctuation:\n",
    "\n",
    "```\n",
    "import string\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "text.translate(translator)\n",
    "```\n",
    "\n",
    "The following questions refer to the text of this book:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b6cf5c-1b16-4d7b-a4da-3451448c87d2",
   "metadata": {},
   "source": [
    "1. Count the number of words (of any length) that only contain letters within the a-g range in the alphabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da771e8-f1e5-4fc3-80f1-8da8fad1bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4827 out of 161005 words match this criterion.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def is_ag(word):\n",
    "    for letter in word:\n",
    "        if letter < 'a' or letter > 'g':\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "ccount = 0\n",
    "tcount = 0\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        words = [w.translate(translator) for w in line.split()]\n",
    "        \n",
    "        for word in words:\n",
    "            tcount += 1\n",
    "            ccount += 1 if is_ag(word) else 0\n",
    "            \n",
    "print(ccount, 'out of', tcount, 'words match this criterion.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd31bd-2a27-4c76-9781-50e008fb2373",
   "metadata": {},
   "source": [
    "2. What is the most frequent of all the words that match the above criterion of only using letters within the range a-g?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe50b4b-674e-43a0-bc5e-15a822b3066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent a-g word is a with 3605 occurrences.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def is_ag(word):\n",
    "    for letter in word:\n",
    "        if letter < 'a' or letter > 'g':\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "wordfreqs = {}\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        words = [w.translate(translator) for w in line.split()]\n",
    "        \n",
    "        for word in words:\n",
    "            if is_ag(word):\n",
    "                wordfreqs[word] = 1 + wordfreqs.get(word, 0)\n",
    "\n",
    "topword = ''\n",
    "topfreq = 0\n",
    "for word, freq in wordfreqs.items():\n",
    "    if freq > topfreq:\n",
    "        topword = word\n",
    "        topfreq = freq\n",
    "    \n",
    "print('The most frequent a-g word is', topword, 'with', topfreq, 'occurrences.')\n",
    "\n",
    "# Alternatively also the following gets the key with max value: max(wordfreqs, key=wordfreqs.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c58a7bc-c8f0-48c8-96e0-09ccad96196b",
   "metadata": {},
   "source": [
    "3. How many lines of the book have at least a number in them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa82c800-7a50-4417-b36c-7f23eaf2f799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "def has_numbers(text):\n",
    "    return any(letter.isdigit() for letter in text)\n",
    "\n",
    "havenumbers = 0\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        havenumbers += 1 if has_numbers(line) else 0\n",
    "            \n",
    "print(havenumbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07adb85f-9f8d-4c1c-95e3-ffbacc5d771a",
   "metadata": {},
   "source": [
    "For the following exercise, you will use the text file with the Romeo and Juliet book (in addition to the Olivier Twist book which you've already downloaded). You can get the text of Romeo and Juliet from https://gutenberg.org/cache/epub/1513/pg1513.txt (again feel free to download it or access it through HTTP request).\n",
    "\n",
    "4. With these two books, after lowercasing and stripping punctuation, identify the number of words that are used in both books, as well as the number of words that are exclusive to each book. You should count each word only once, regardless of its number of occurrences within a book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28407ec5-c851-42f6-9a41-4597f03b7b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common words: 2795\n",
      "Exclusive to OT: 11550\n",
      "Exclusive to R&J: 2141\n"
     ]
    }
   ],
   "source": [
    "# option 1: recommended\n",
    "otwords = []\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        otwords.extend([w.translate(translator) for w in line.split()])\n",
    "        \n",
    "rjwords = []\n",
    "with open('files/pg1513.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        rjwords.extend([w.translate(translator) for w in line.split()])\n",
    "\n",
    "commonwords = len(set(otwords) & set(rjwords))\n",
    "print('Common words: ' + str(commonwords))\n",
    "\n",
    "otexclusive = len(set(otwords) - set(rjwords))\n",
    "print('Exclusive to OT: ' + str(otexclusive))\n",
    "\n",
    "rjexclusive = len(set(rjwords) - set(otwords))\n",
    "print('Exclusive to R&J: ' + str(rjexclusive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "691225ee-a8b6-42e4-807d-138ba6da0c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11550\n",
      "2141\n",
      "2795\n"
     ]
    }
   ],
   "source": [
    "# option 2: VERY SLOW AND INEFFICIENT, NOT RECOMMENDED\n",
    "otwords = []\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        otwords.extend([w.translate(translator) for w in line.split()])\n",
    "        \n",
    "rjwords = []\n",
    "with open('files/pg1513.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        rjwords.extend([w.translate(translator) for w in line.split()])\n",
    "        \n",
    "onlyot = []\n",
    "for word in otwords:\n",
    "    if word not in rjwords and word not in onlyot:\n",
    "        onlyot.append(word)\n",
    "        \n",
    "print(len(onlyot))\n",
    "\n",
    "onlyrj = []\n",
    "for word in rjwords:\n",
    "    if word not in otwords and word not in onlyrj:\n",
    "        onlyrj.append(word)\n",
    "        \n",
    "print(len(onlyrj))\n",
    "\n",
    "common = []\n",
    "for word in rjwords:\n",
    "    if word in otwords and word not in common:\n",
    "        common.append(word)\n",
    "        \n",
    "print(len(common))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd4d05-d745-413e-9a73-140acf1fe58b",
   "metadata": {},
   "source": [
    "For the following exercises, you will use a dataset comprising food hygiene ratings pertaining to over 600k businesses across the UK. This is a real dataset obtained from the UK's Food Standards Agency, where each business is rated with a score from 0 (urgent improvement necessary) to 5 (very good). The dataset is provided in json format, in a file called 'food-hygiene-ratings.json'. Each entry in the dataset contains a business which, in addition to the hygiene rating score, provides information on the business type, its address, its local authority, etc.\n",
    "\n",
    "The following questions are to be answered by using this dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee52e91-a4e1-4066-ba01-2d00c3f5ee33",
   "metadata": {},
   "source": [
    "5. If we group businesses by their local authority area (the 'LocalAuthorityName' field), what is the area with lower average rating across all its businesses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e76a6242-77aa-48d0-bc97-d2fa9cf0ad0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local authority area with the lowest average rating is 'Waltham Forest' with an average rating of 3.874604847207587\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "arearatings = {}\n",
    "avgratings = {}\n",
    "with open('food-hygiene-ratings.json', 'r') as fh:\n",
    "    for line in fh:\n",
    "        business = json.loads(line)\n",
    "        \n",
    "        if business['RatingValue'].isnumeric() and not business['LocalAuthorityName'] in arearatings:\n",
    "            arearatings[business['LocalAuthorityName']] = []\n",
    "            avgratings[business['LocalAuthorityName']] = []\n",
    "        if business['RatingValue'].isnumeric():\n",
    "            arearatings[business['LocalAuthorityName']].append(int(business['RatingValue']))\n",
    "            \n",
    "for area, ratings in arearatings.items():\n",
    "    avgratings[area] = sum(ratings) / len(ratings)\n",
    "    \n",
    "minarea = min(avgratings, key=avgratings.get)\n",
    "\n",
    "print('The local authority area with the lowest average rating is \\'' + minarea + '\\' with an average rating of ' + str(avgratings[minarea]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba999ee9-ec1d-43a0-a1d1-ce30b03dd69c",
   "metadata": {},
   "source": [
    "6. The 'RatingDate' indicates the date in which the Food Standards Agency last inspected a business. Using the information in this field for all businesses, produce a ranking of the months where the Food Standards Agency conducts its inspection (ranked from most to least)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "990bdcd7-91fd-4c9f-8b9e-e56ae05a9f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03: 61960 inspections.\n",
      "02: 54813 inspections.\n",
      "06: 52720 inspections.\n",
      "05: 50352 inspections.\n",
      "07: 50268 inspections.\n",
      "01: 50238 inspections.\n",
      "11: 47918 inspections.\n",
      "10: 42278 inspections.\n",
      "04: 40843 inspections.\n",
      "09: 39172 inspections.\n",
      "08: 38151 inspections.\n",
      "12: 28710 inspections.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "months = {}\n",
    "with open('food-hygiene-ratings.json', 'r') as fh:\n",
    "    for line in fh:\n",
    "        business = json.loads(line)\n",
    "        \n",
    "        if isinstance(business['RatingDate'], str):\n",
    "            month = business['RatingDate'].split('-')[1]\n",
    "            months[month] = 1 + months.get(month, 0)\n",
    "\n",
    "months = {k: v for k, v in sorted(months.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "for month in months:\n",
    "    print(month + ': ' + str(months[month]) + ' inspections.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
